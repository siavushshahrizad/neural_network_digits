{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from PIL.ImageShow import show\n",
    "from PIL.Image import Image\n",
    "from typing import List, Union\n",
    "import random\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ALPHA = 0.01\n",
    "NORMALISATION = 255\n",
    "BATCH_SIZE = 16\n",
    "NO_NEURONS_LAYER_0 = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first label is a 5.\n",
      "There are 784 pixels in the first image.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data set\n",
    "train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=None)\n",
    "\n",
    "# Get first image data and target \n",
    "train_image_zero, train_target_zero = train_data[0]\n",
    "image_zero_pixels = train_image_zero.getdata()\n",
    "number_pixels = len(image_zero_pixels)\n",
    "\n",
    "# Display image\n",
    "train_image_zero.show()\n",
    "print(f\"The first label is a {train_target_zero}.\")\n",
    "print(f\"There are {number_pixels} pixels in the first image.\")\n",
    "\n",
    "# Transform data for later to standard list, not pytorch object\n",
    "train_data = [(image, label) for image, label in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code avoids libraries to build understanding  of neural networks under \n",
    "# the hood. The functions that follow in subsequent cells are used by the\n",
    "# network to make predictions. \n",
    "\n",
    "def initialise_random_weights(m=NO_NEURONS_LAYER_0, n=number_pixels):\n",
    "    \"\"\"\n",
    "    Initializes a matrix of random weights for a layer in a neural network \n",
    "    randomly between -0.5 and 0.5. The weights matrix will be of shape (m, n)\n",
    "\n",
    "    Args:\n",
    "        m (int): The number of neurons in the layer (default is NO_NEURONS_LAYER_0).\n",
    "        n (int): The number of input features (default is number_pixels, representing \n",
    "               the number of pixels in an input image, e.g., 784 for MNIST).\n",
    "\n",
    "    Returns:\n",
    "        List[List[float]]: A matrix of shape (m, n)        \n",
    "    \"\"\"\n",
    "    return [[random.uniform(-0.5, 0.5) for _ in range(n)] for _ in range(m)]\n",
    "\n",
    "def w_sum(inputs: List[List[Union[float, int]]], weights: List[List[float]]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Calculates a weighted sum or dot product for a batch of data. The number\n",
    "    of input features needs to be same as number of weights per neuron. \n",
    "\n",
    "    Args:\n",
    "        inputs (List[List[Union[float, int]]]): A matrix of features for each sample\n",
    "        weights (List[List[float]]): Weights for each feature by number of neurons\n",
    "\n",
    "    Returns:\n",
    "        List[List[float]]: A matrix of dot product for each neuron per sample in batch\n",
    "    \"\"\"\n",
    "    num_neurons = len(weights)\n",
    "    batch_size = len(inputs)\n",
    "    num_features = len(inputs[0])\n",
    "\n",
    "    outputs = [[0] * batch_size for _ in range(num_neurons)]\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(batch_size):\n",
    "            outputs[i][j] = sum(inputs[j][k] * weights[i][k] for k in range(num_features))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for above functions\n",
    "def test_initialise_random_weights():\n",
    "    weights = initialise_random_weights()\n",
    "    assert len(weights) == NO_NEURONS_LAYER_0\n",
    "    assert len(weights[0]) == number_pixels\n",
    "    \n",
    "def test_w_sum():\n",
    "    inputs = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]\n",
    "    weights = [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]]\n",
    "    outputs = w_sum(inputs, weights)\n",
    "    expected_outputs = [[1.4, 3.2], [3.2, 7.7]]\n",
    "    \n",
    "    for i in range(len(outputs)):\n",
    "        for j in range(len(outputs[i])):\n",
    "            assert outputs[i][j] == pytest.approx(expected_outputs[i][j], rel=1e-9), f\"Mismatch at {i}, {j}\"\n",
    "\n",
    "# Run tests\n",
    "test_initialise_random_weights()\n",
    "test_w_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deltas(predicted_labels: List[float], labels: List[Union[float, int]]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Calculates absolute deviation of predicted from actual labels. The number of predicted and \n",
    "    actual label needs to be the same. \n",
    "        \n",
    "    Args:\n",
    "        predicted_labels (List[Union[float, int]]): A list of predicted labels per sample in batch\n",
    "        labels (List[float]): A list of actual labels per sample in batch \n",
    "\n",
    "    Returns:\n",
    "        deltas (List[float]): A List of absolute deviation between predicted and actual labels\n",
    "\n",
    "    \"\"\"\n",
    "    batch_size = len(predicted_labels)\n",
    "\n",
    "    if len(labels) != batch_size:\n",
    "        raise ValueError(\"Vectors need to be of same len\")\n",
    "\n",
    "    deltas = [0] * batch_size\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        deltas[i] = predicted_labels[i] - labels[i]\n",
    "\n",
    "    return deltas\n",
    "\n",
    "def calculate_errors(deltas: List[float]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Calculates the squared error for each delta in the batch.\n",
    "        \n",
    "    Args:\n",
    "        deltas (List[float]): A list of differences between predicted and actual labels for each sample in the batch.\n",
    "    \n",
    "    Returns:\n",
    "        errors (List[float]): A list of squared errors for each sample, representing the square of the delta values.\n",
    "    \"\"\"\n",
    "    batch_size = len(deltas)\n",
    "    errors = [0] * batch_size\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        errors[i] = deltas[i] ** 2\n",
    "\n",
    "    return errors\n",
    "    \n",
    "def calculate_weight_deltas(inputs: List[List[Union[float, int]]], deltas: List[float]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Calculates weight deltas for each feature in each sample of the batch, using the product of\n",
    "    the feature value and the delta for that sample. This forms the basis for adjusting weights\n",
    "    during backpropagation by providing the per-feature correction needed for each sample.\n",
    "        \n",
    "    Args:\n",
    "        inputs (List[List[Union[float, int]]]): A matrix of input features where each row \n",
    "            represents a sample in the batch and each column represents a feature.\n",
    "        deltas (List[float]): A list of deltas for each sample in the batch, representing the deviation \n",
    "            of predictions from actual values.\n",
    "    \n",
    "    Returns:\n",
    "        weight_deltas (List[List[float]]): A matrix where each row contains the weight deltas \n",
    "            for a sample in the batch, with each element in the row representing the delta for a feature.\n",
    "    \"\"\"\n",
    "    batch_size = len(inputs)\n",
    "    num_features = len(inputs[0])\n",
    "\n",
    "    weight_deltas = [[0] * num_features for _ in range(batch_size)]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(num_features):\n",
    "            weight_deltas[i][j] = inputs[i][j] * deltas[i]\n",
    "    \n",
    "    return weight_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4, -8, -12], [-12, -15, -18]]\n"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "def test_calculate_deltas():\n",
    "    assert calculate_deltas([1, 2, 3], [5, 5, 5]) == [-4, -3, -2]\n",
    "\n",
    "def test_calculate_errors():\n",
    "    assert calculate_errors([-4, -3, -2]) == [16, 9, 4]\n",
    "\n",
    "def test_calculate_weight_deltas():\n",
    "    result = calculate_weight_deltas([[1, 2, 3], [4, 5, 6]], [-4, -3])\n",
    "    expected = [[-4, -8, -12], [-12, -15, -18]]\n",
    "    assert  result == expected\n",
    "\n",
    "# Run tests\n",
    "test_calculate_deltas()\n",
    "test_calculate_errors()\n",
    "test_calculate_weight_deltas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(inputs, weights, targets):\n",
    "    preds = w_sum(inputs, weights) \n",
    "    deltas = [calculate_deltas(preds_per_neuron, targets) for preds_per_neuron in preds] \n",
    "    errors = [calculate_errors(deltas_per_neuron) for deltas_per_neuron in deltas]\n",
    "    weight_deltas = [calculate_weight_deltas(inputs, deltas_per_neuron) for deltas_per_neuron in deltas]\n",
    "    return preds, errors, weight_deltas\n",
    "\n",
    "def back_propagation(weights: List[List[float]], weight_deltas: List[List[List[float]]]) -> None:\n",
    "    num_neurons = len(weights)\n",
    "    num_weights = len(weights[0])\n",
    "    batch_size = len(weight_deltas[0])\n",
    "    avg_deltas = []\n",
    "    \n",
    "    for i in range(num_neurons):\n",
    "        avg_deltas_for_neuron = [0] * num_weights\n",
    "\n",
    "        for j in range(num_weights):\n",
    "            for k in range(batch_size):\n",
    "                avg_deltas_for_neuron[j] += weight_deltas[i][k][j] / batch_size\n",
    "\n",
    "        avg_deltas.append(avg_deltas_for_neuron)\n",
    "\n",
    "    updated_weights = [[weights[i][j] - ALPHA * avg_deltas[i][j] for j in range(num_weights)] for i in range(num_neurons)]\n",
    "    \n",
    "    return updated_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "def test_forward_propagation():\n",
    "    inputs = [[1, 2, 3], [4, 5, 3]]\n",
    "    weights = [[1, 2, 2], [2, 1, 1], [1, 2, 1]]\n",
    "    targets = [2, 4]\n",
    "    preds, errors, weight_detltas = forward_propagation(inputs, weights, targets)\n",
    "    expected_preds = [[11, 20], [7, 16], [8, 17]]\n",
    "    expected_errors = [[81, 256], [25, 144], [36, 169]]\n",
    "    expected_weight_deltas = [[[9, 18, 27], [64, 80, 48]], [[5, 10, 15], [48, 60, 36]], [[6, 12, 18], [52, 65, 39]]]\n",
    "    assert preds == expected_preds\n",
    "    assert errors == expected_errors\n",
    "    assert weight_detltas == expected_weight_deltas\n",
    "\n",
    "def test_back_propagation():\n",
    "    weights = [[1, 2, 2], [2, 1, 1], [1, 2, 1]]\n",
    "    weight_deltas = [[[9, 18, 27], [64, 80, 48]], [[5, 10, 15], [48, 60, 36]], [[6, 12, 18], [52, 65, 39]]]\n",
    "    result = back_propagation(weights, weight_deltas)\n",
    "    expected = [[0.635, 1.51, 1.625], [1.7349999999999999, 0.6499999999999999, 0.745], [0.71, 1.615, 0.715]]\n",
    "    assert result == expected\n",
    "\n",
    "# Run tests\n",
    "test_forward_propagation()\n",
    "test_back_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    weights = [[random.uniform(-0.5, 0.5) for _ in range(number_pixels)] for _ in range(NO_NEURONS_LAYER_0)]\n",
    "    \n",
    "    for i in range(0, len(train_data), BATCH_SIZE):\n",
    "        batch = train_data[i: i + BATCH_SIZE]\n",
    "        input_data = [[pixel / NORMALISATION for pixel in list(x[0].getdata())] for x in batch]\n",
    "        targets = [x[1] for x in batch] \n",
    "\n",
    "        preds, errors, weight_deltas  = forward_propagation(input_data, weights, targets)\n",
    "        weights = back_propagation(weights, weight_deltas)\n",
    "        \n",
    "        batch_mse = sum(sum(error for error in neuron_errors) / len(neuron_errors) for neuron_errors in errors) / NO_NEURONS_LAYER_0\n",
    "\n",
    "        if i % (100 * BATCH_SIZE) == 0: \n",
    "            print(f\"Batch {(i / BATCH_SIZE) + 1} with Avg MSE: {batch_mse}\")\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1.0 with Avg MSE: 24.172855841331703\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m input_data \u001b[38;5;241m=\u001b[39m [[pixel \u001b[38;5;241m/\u001b[39m NORMALISATION \u001b[38;5;28;01mfor\u001b[39;00m pixel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mgetdata())] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      7\u001b[0m targets \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch] \n\u001b[0;32m----> 9\u001b[0m preds, errors, weight_deltas  \u001b[38;5;241m=\u001b[39m \u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m weights \u001b[38;5;241m=\u001b[39m back_propagation(weights, weight_deltas)\n\u001b[1;32m     12\u001b[0m batch_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28msum\u001b[39m(error \u001b[38;5;28;01mfor\u001b[39;00m error \u001b[38;5;129;01min\u001b[39;00m neuron_errors) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(neuron_errors) \u001b[38;5;28;01mfor\u001b[39;00m neuron_errors \u001b[38;5;129;01min\u001b[39;00m errors) \u001b[38;5;241m/\u001b[39m NO_NEURONS_LAYER_0\n",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m, in \u001b[0;36mforward_propagation\u001b[0;34m(inputs, weights, targets)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_propagation\u001b[39m(inputs, weights, targets):\n\u001b[0;32m----> 2\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mw_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      3\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m [calculate_deltas(preds_per_neuron, targets) \u001b[38;5;28;01mfor\u001b[39;00m preds_per_neuron \u001b[38;5;129;01min\u001b[39;00m preds] \n\u001b[1;32m      4\u001b[0m     errors \u001b[38;5;241m=\u001b[39m [calculate_errors(deltas_per_neuron) \u001b[38;5;28;01mfor\u001b[39;00m deltas_per_neuron \u001b[38;5;129;01min\u001b[39;00m deltas]\n",
      "Cell \u001b[0;32mIn[18], line 40\u001b[0m, in \u001b[0;36mw_sum\u001b[0;34m(inputs, weights)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_neurons):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m---> 40\u001b[0m         outputs[i][j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "Cell \u001b[0;32mIn[18], line 40\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_neurons):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m---> 40\u001b[0m         outputs[i][j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(inputs[j][k] \u001b[38;5;241m*\u001b[39m weights[i][k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights = train(train_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweet-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

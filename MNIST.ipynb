{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below avoids libraries as much as possible to build understanding \n",
    "# of what methods do and how neural networks work under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from PIL.ImageShow import show\n",
    "from PIL.Image import Image\n",
    "from typing import List, Union\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ALPHA = 0.01\n",
    "NORMALISATION = 255\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first label is a 5.\n",
      "There are 784 pixels in the first image.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data set\n",
    "train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=None)\n",
    "\n",
    "# Get first image data and target and display image\n",
    "train_image_zero, train_target_zero = train_data[0]\n",
    "image_zero_pixels = train_image_zero.getdata()\n",
    "number_pixels = len(image_zero_pixels)\n",
    "\n",
    "train_image_zero.show()\n",
    "print(f\"The first label is a {train_target_zero}.\")\n",
    "print(f\"There are {number_pixels} pixels in the first image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to train neural net \n",
    "def w_sum(inputs: List[List[Union[float, int]]], weights: List[Union[float, int]]) -> List[Union[float, int]]:\n",
    "    m = len(inputs)\n",
    "    n = len(weights)\n",
    "    if len(inputs[0]) != n:\n",
    "        raise ValueError(\"Vectors need to be of same len\")\n",
    "    \n",
    "    outputs = [0] * m\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            outputs[i] += inputs[i][j] * weights[j]\n",
    "    return outputs\n",
    "\n",
    "def calculate_deltas(predicted_labels: List[Union[float, int]], labels: List[Union[float, int]]) -> List[Union[float, int]]:\n",
    "    n = len(predicted_labels)\n",
    "\n",
    "    if len(labels) != n:\n",
    "        raise ValueError(\"Vectors need to be of same len\")\n",
    "\n",
    "    deltas = [0] * n\n",
    "\n",
    "    for i in range(n):\n",
    "        deltas[i] = predicted_labels[i] - labels[i]\n",
    "\n",
    "    return deltas\n",
    "\n",
    "def calculate_errors(deltas: List[float]) -> List[float]:\n",
    "    n = len(deltas)\n",
    "    errors = [0] * n\n",
    "\n",
    "    for i in range(n):\n",
    "        errors[i] = deltas[i] ** 2\n",
    "\n",
    "    return errors\n",
    "\n",
    "def neural_network(inputs, weights, targets):\n",
    "    preds = w_sum(inputs, weights)\n",
    "    deltas = calculate_deltas(preds, targets)\n",
    "    errors = calculate_errors(deltas)\n",
    "    \n",
    "    return preds, deltas, errors\n",
    "    \n",
    "def calculate_weight_deltas(inputs: List[Union[float, int]], deltas: List[float]) -> List[List[float]]:\n",
    "    m = len(inputs)\n",
    "    n = len(inputs[0])\n",
    "\n",
    "    #     # Debugging statements\n",
    "    # print(f\"inputs shape: ({m}, {n})\")\n",
    "    # print(f\"deltas length: {len(deltas)}\")\n",
    "    # print(f\"deltas content: {deltas}\")\n",
    "\n",
    "    # if len(deltas) != n:\n",
    "    #     raise ValueError(\"Length of deltas must match the number of features (columns) in inputs.\")\n",
    "\n",
    "    weight_deltas = [[0] * n for _ in range(m)]\n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            weight_deltas[i][j] = inputs[i][j] * deltas[i]\n",
    "    \n",
    "    return weight_deltas\n",
    "\n",
    "def back_propagation(weights: List[Union[float, int]], weight_deltas: List[List[float]]) -> None:\n",
    "    length = len(weights)\n",
    "    avg_deltas = [0] * length   \n",
    "\n",
    "    for i in range(length):\n",
    "        for delta in weight_deltas:\n",
    "            avg_deltas[i] += delta[i] / len(weight_deltas)\n",
    "\n",
    "    for i in range(length):\n",
    "        weights[i] -= ALPHA * avg_deltas[i]\n",
    "\n",
    "def forward_propagation(inputs, weights, target):\n",
    "    preds, deltas, errors = neural_network(inputs, weights, target)\n",
    "    weight_deltas = calculate_weight_deltas(inputs, deltas)                                       \n",
    "    back_propagation(weights, weight_deltas)\n",
    "    return preds, errors\n",
    "\n",
    "def train(data):\n",
    "    weights = [random.uniform(-0.5, 0.5) for _ in range(number_pixels)]\n",
    "\n",
    "    for i in range(0, len(train_data), BATCH_SIZE):\n",
    "        batch = train_data[i: i + BATCH_SIZE]\n",
    "        input_data = [[pixel / NORMALISATION for pixel in list(x[0].getdata())] for x in batch]\n",
    "        targets = [x[1] for x in batch] \n",
    "\n",
    "        pred, error = forward_propagation(input_data, weights, targets)\n",
    "\n",
    "        if i % (100 * BATCH_SIZE) == 0: \n",
    "            print(f\"Batch {(i / BATCH_SIZE) + 1}: Last batch pred: {pred[-1]}, Last batch target: {targets[-1]}, Avg error: {sum(error) / len(error)}\")\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up test functions\n",
    "def test_w_sum():\n",
    "    assert w_sum([[1, 2, 3], [4, 5, 6]], [1, 2, 3]) == [14, 32]\n",
    "\n",
    "def test_calculate_deltas():\n",
    "    assert calculate_deltas([1, 2, 3], [5, 5, 5]) == [-4, -3, -2]\n",
    "\n",
    "def test_calculate_errors():\n",
    "    assert calculate_errors([-4, -3, -2]) == [16, 9, 4]\n",
    "\n",
    "def test_calculate_weight_deltas():\n",
    "    assert calculate_weight_deltas([[1, 2, 3], [4, 5, 6]], [-4, -3, -2]) == [[-4, -6, -6], [-16, -15, -12]]\n",
    "\n",
    "def test_back_propagation():\n",
    "    weights = [1, 2, 3]\n",
    "    weight_deltas = [[-4, -6, -6], [-16, -15, -12]]\n",
    "    back_propagation(weights, weight_deltas)\n",
    "    assert weights == [1.1, 2.105, 3.09]\n",
    "\n",
    "# Run tests\n",
    "test_w_sum()\n",
    "test_calculate_errors()\n",
    "test_calculate_deltas()\n",
    "test_calculate_weight_deltas()\n",
    "test_back_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1.0: Last batch pred: -1.0613820536515812, Last batch target: 7, Avg error: 30.865630027126244\n",
      "Batch 101.0: Last batch pred: 2.9815932818995816, Last batch target: 5, Avg error: 4.265678021389187\n",
      "Batch 201.0: Last batch pred: 0.8980639537703442, Last batch target: 3, Avg error: 6.693346798378457\n",
      "Batch 301.0: Last batch pred: 0.028064552322429114, Last batch target: 1, Avg error: 5.780141476148991\n",
      "Batch 401.0: Last batch pred: 1.8464604327098315, Last batch target: 3, Avg error: 2.2268141224850995\n",
      "Batch 501.0: Last batch pred: 8.13119043336007, Last batch target: 9, Avg error: 4.3254348371116365\n",
      "Batch 601.0: Last batch pred: 1.087057073033319, Last batch target: 1, Avg error: 4.126560449848958\n",
      "Batch 701.0: Last batch pred: 7.298928494298924, Last batch target: 9, Avg error: 5.929020699520281\n",
      "Batch 801.0: Last batch pred: -0.477930246857102, Last batch target: 2, Avg error: 1.5688087747529753\n",
      "Batch 901.0: Last batch pred: 7.385143398519008, Last batch target: 4, Avg error: 7.296864947656534\n",
      "Batch 1001.0: Last batch pred: 6.9169309643026935, Last batch target: 7, Avg error: 3.148802914559803\n",
      "Batch 1101.0: Last batch pred: 6.0897008721628705, Last batch target: 7, Avg error: 4.631659667766469\n",
      "Batch 1201.0: Last batch pred: 5.8842211346551165, Last batch target: 3, Avg error: 7.881216757151476\n",
      "Batch 1301.0: Last batch pred: 4.780235900127845, Last batch target: 5, Avg error: 3.888261073406114\n",
      "Batch 1401.0: Last batch pred: 0.9656106287807358, Last batch target: 3, Avg error: 4.5478886233167275\n",
      "Batch 1501.0: Last batch pred: 3.656895402332235, Last batch target: 2, Avg error: 4.633935770002886\n",
      "Batch 1601.0: Last batch pred: 5.799067385008221, Last batch target: 7, Avg error: 2.1011915626424797\n",
      "Batch 1701.0: Last batch pred: 2.7067460816007545, Last batch target: 2, Avg error: 4.909571375215526\n",
      "Batch 1801.0: Last batch pred: 1.6572665436123888, Last batch target: 1, Avg error: 4.1903199883053155\n",
      "Batch 1901.0: Last batch pred: 6.1133111406400795, Last batch target: 8, Avg error: 3.9789584381616296\n",
      "Batch 2001.0: Last batch pred: 5.946789207212302, Last batch target: 4, Avg error: 6.984293118377651\n",
      "Batch 2101.0: Last batch pred: 5.093734682576025, Last batch target: 6, Avg error: 4.517400040870013\n",
      "Batch 2201.0: Last batch pred: 5.823041852835717, Last batch target: 2, Avg error: 4.65245456375952\n",
      "Batch 2301.0: Last batch pred: 6.483157702995685, Last batch target: 3, Avg error: 3.9620655364299466\n",
      "Batch 2401.0: Last batch pred: 1.72866060121891, Last batch target: 1, Avg error: 4.133332826284747\n",
      "Batch 2501.0: Last batch pred: 1.7709678267825324, Last batch target: 1, Avg error: 3.1997434864731122\n",
      "Batch 2601.0: Last batch pred: 4.382619487114553, Last batch target: 7, Avg error: 4.183707097357344\n",
      "Batch 2701.0: Last batch pred: 7.19156115771849, Last batch target: 8, Avg error: 5.260090876905126\n",
      "Batch 2801.0: Last batch pred: 1.3961031989327315, Last batch target: 0, Avg error: 2.471381886839933\n",
      "Batch 2901.0: Last batch pred: 5.561941467442143, Last batch target: 4, Avg error: 4.43386893030638\n",
      "Batch 3001.0: Last batch pred: 5.969758668430153, Last batch target: 4, Avg error: 2.8644015343864457\n",
      "Batch 3101.0: Last batch pred: 7.324054122510132, Last batch target: 7, Avg error: 4.215693637129242\n",
      "Batch 3201.0: Last batch pred: 1.6311054436326604, Last batch target: 0, Avg error: 5.519728825845547\n",
      "Batch 3301.0: Last batch pred: 4.34645895811062, Last batch target: 4, Avg error: 5.296412901875301\n",
      "Batch 3401.0: Last batch pred: 3.082580080966747, Last batch target: 4, Avg error: 1.902305678213237\n",
      "Batch 3501.0: Last batch pred: 7.150728632909849, Last batch target: 6, Avg error: 1.5948395057086138\n",
      "Batch 3601.0: Last batch pred: 1.4751619647682364, Last batch target: 2, Avg error: 2.353585439459088\n",
      "Batch 3701.0: Last batch pred: 7.11715514586122, Last batch target: 8, Avg error: 1.6180129334597835\n"
     ]
    }
   ],
   "source": [
    "train_data = [(image, label) for image, label in train_data]\n",
    "weights = train(train_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweet-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
